{
    "url": "https://cs.uic.edu/profiles/xinhua-zhang/",
    "title": "Zhang, Xinhua  | Department of Computer Science | University of Illinois at Chicago",
    "text": [
        "Assistant Professor",
        "",
        "Department of Computer Science",
        "Daley Library 3-190 G",
        "801 S Morgan St, Chicago, IL 60607",
        "(312) 413-2416",
        "zhangx@uic.edu",
        "My current research in machine learning focuses on convex models for learning predictive representation. Most existing machine learning methods infer representation from data in a way that is independent of its subsequent use, e.g. learning a predictive model. This is suboptimal. My research goal is to jointly infer latent representation and learn predictors for massive datasets by combining them into a single convex optimization problem. Convexity allows jointly optimal solutions to be found for these two tasks, and scale up efficiently to large application problems. To achieve this goal, my key strategies are: 1) find appropriate convex relaxations that retain the structure of the data, e.g. semi-definite relaxations; and 2) design efficient algorithms for optimization such as low-rank approximation.",
        "I work on applications in pattern recognition, document analysis, image processing, and any prediction problem that is useful in life.",
        "Prior to joining UIC in Nov 2015, I was a Senior Researcher at the Machine Learning Research Group of National ICT Australia (NICTA, now Data61). From April 2010 to September 2012, I was a post-doc working with Prof Dale Schuurmans at the Department of Computing Science, University of Alberta.  From March 2006 to October 2009, I was a NICTA-endorsed PhD student of the Research School of Computer Science, Australian National University (ANU), working with Prof SVN Vishwanathan and Prof Alex Smola.  I visited Prof SVN Vishwanathan at the Department of Statistics at Purdue University from February 2009 to March 2010.  From January 2004 to March 2006, I pursued my Master's degree (by research) under the supervision of Prof Wee Sun Lee at theDepartment of Computer Science, National University of Singapore (NUS). I received my B.E. from the Department of Computer Science and Engineering atShanghai Jiao Tong University in July 2003. My hometown is Shanghai.",
        "1",
        "Generalized Conditional Gradient (GCG)",
        "[link]",
        "GCG is an open source Matlab solver for gauge (norm) regularized problems, that are commonly used in sparse coding and compressive sensing.  Examples include matrix completion, dictionary learning, and structured sparse estimation.",
        "2",
        "Smoothing for Multivariate Scores (SMS)",
        "[link]",
        "SMS is an open source, extensible and scalable convex solver for a number of machine learning problems cast in the form of regularized risk minimization problem. It is particularly advantageous for optimizing multivariate performance measure. The implementation is \"extensible\" because the (problem-specific) loss function modules are encapsulated with a common interface for the main optimizer. Thus it is very simple to incorporate solutions to new problems.",
        "3",
        "Convex Subspace Learning",
        "[link]",
        "This Matlab package implements the convex subspace learning model proposed at NIPS'12 and AAAI'12. The optimization is based on alternating direction of multiplier method. Example applications include semi-supervised learning, image denoising, and multi-label learning.",
        "4",
        "Bayesian Online Multilabel Classification (BOMC)",
        "[link]",
        "BOMC is an open source toolkit for online multilabel classification using Bayesian models. It is implemented in F# 1.9.3.4 on Microsoft Visual Studio 2008, and can be compiled and run on Linux systems via Mono. The graphical model is extend from TrueSkillTM [2] to deal with multilabel, and the inference engine is expectation propagation.",
        "5",
        "Conditional Random Fields for Policy Gradient Multi-agent Reinforcement Learning",
        "[tar.bz2  700 KB] [paper]",
        "This package implements the tree sampling for inference in conditional random fields.  With the sampled states and approximate expectations, the package implements the natural actor-critic which performs collaborative multi-agent reinforcement learning.  Three simulators are provided namely grid gate control, sensor network, and traffic light control.",
        "6",
        "Faster Rates for Training SVMs using Optimal Gradient based Methods",
        "[tar.bz2  800 KB] [paper]",
        "This package implements the three versions of Nesterov's first-order methods proposed in 1983, 2005 and 2007.  Its rate of convergence is O(1/k^2), which is proved to be optimal in this class of optimizers.  The 1983 version optimizes a smooth function with Lipschitz continuous gradient.  The 2005 version extends to the primal-dual setting, and the 2007 version can automatically estimate the unknown Lipschitz constant of the gradient.This code is built upon the package BMRM.",
        "7",
        "Hyperparameter Learning for Graph based Semi-supervised Learning Algorithms",
        "[tar  100 KB] [paper]",
        "This package implements the leave-one-out method for learning the hyperparameters in graph based semi-supervised learning.  Practical efficiency is achieved via the Sherman–Morrison formula and by facting out the common terms in feature weight updates.This code relies on the math library of Matlab.  See this link for details.",
        "University of Illinois at Chicago",
        "Fall 2018",
        "CS412 Introduction to Machine Learning  (Syllabus)",
        "Spring 2018",
        "CS594 Advanced Machine Learning  (Syllabus)",
        "Fall 2017",
        "CS412 Introduction to Machine Learning  (Syllabus)",
        "Spring 2017",
        "CS411 Artificial Intelligence I  (Syllabus)",
        "Fall 2016",
        "CS594 Advanced Topics in Machine Learning  (Syllabus)",
        "Project of training CRFs using TAO and Torch  [.PDF, .zip]",
        "Spring 2016",
        "CS411 Artificial Intelligence I  (Syllabus)",
        "",
        "Australian National University",
        "2015",
        "COMP2610/6261 Information Theory",
        "co-taught with Aditya Menon and Mark Reid",
        "2014 &",
        "2013",
        "COMP4680/8650 Advanced Topics in Statistical Machine Learning",
        "co-taught with Stephen Gould and Justin Domke",
        "My lecture notes on Bregman divergence and mirror descent are here.",
        "Purdue University",
        "2009",
        "Guest lecture at STAT 598Y (Statistical Learning Theorey)",
        "My lecture notes on accelerated gradient methods are here.",
        "Refereed Journal Papers",
        "1",
        "Yaoliang Yu, Xinhua Zhang, Dale Schuurmans",
        "Generalized Conditional Gradient for Sparse Estimation",
        "Journal of Machine Learning Research (JMLR)"